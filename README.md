# ğŸ™ï¸ CNN Audio Classification - Schizophrenia Detection

**Deep Learning-based Audio Classification System for Mental Health Screening**

Developed for RSJD dr. Amino Gondohutomo

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.20-orange.svg)](https://www.tensorflow.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.50-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“Š Model Performance

| Metric | Value | Status |
|--------|-------|--------|
| **Validation Accuracy** | 93.48% | âœ… Excellent |
| **Precision** | 87.50% | âœ… Very Good |
| **Recall** | 100.00% | ğŸŒŸ Perfect |
| **ROC-AUC** | 99.90% | ğŸ† Outstanding |

**No false negatives** - Critical for medical screening applications!

---

## ğŸ¯ Features

### ğŸ” Security & Authentication (NEW!)
- âœ… **User Authentication**: Secure login system with PBKDF2-SHA256 password hashing
- âœ… **Role-Based Access Control**: Admin, Doctor, and Staff roles
- âœ… **Session Management**: 30-minute auto-logout for security
- âœ… **Audit Logging**: Complete login history tracking
- âœ… **Admin Panel**: User management dashboard

### ğŸ¤– Machine Learning
- âœ… **Binary Classification**: Normal vs Skizofrenia
- âœ… **Deep CNN Architecture**: 4 convolutional blocks with batch normalization
- âœ… **Advanced Data Augmentation**: 5 techniques (noise, pitch shift, time stretch, reverb, time shift)
- âœ… **Comprehensive Metrics**: Accuracy, Precision, Recall, F1, AUC, ROC
- âœ… **Production Ready**: Early stopping, model checkpointing, adaptive learning rate

### ğŸ¨ User Interface
- âœ… **Modern Web Interface**: Streamlit app with gauge meters and interactive charts
- âœ… **Clean Login Page**: Professional authentication UI
- âœ… **Real-time Visualization**: Audio waveform and spectrogram
- âœ… **Responsive Design**: Works on desktop and tablets

### ğŸ“± Mobile Deployment
- âœ… **TensorFlow Lite**: Optimized model (1.24MB quantized)
- âœ… **Flutter Guide**: Complete offline mobile app documentation
- âœ… **Cross-platform**: Android & iOS support

---

## ğŸ—ï¸ Architecture

### Model Overview
- **Type**: Deep Convolutional Neural Network (CNN)
- **Input**: Mel Spectrogram (128 x 216)
- **Parameters**: ~3M
- **Layers**: 
  - 4 Conv2D blocks (32 â†’ 64 â†’ 128 â†’ 256 filters)
  - Batch Normalization after each layer
  - Dropout for regularization
  - Global Average Pooling
  - Dense layers with sigmoid output

### Data Pipeline
```
Raw Audio (.wav/.mp3/.ogg)
    â†“
Librosa Feature Extraction (Mel Spectrogram)
    â†“
Data Augmentation (7x multiplication)
    â”œâ”€ Add Noise
    â”œâ”€ Time Shift
    â”œâ”€ Pitch Shift
    â”œâ”€ Time Stretch
    â””â”€ Reverb
    â†“
CNN Model (Binary Classification)
    â†“
Prediction (Normal / Skizofrenia)
```

---

## ğŸ“ Project Structure

```
CNN_amino/
â”‚
â”œâ”€â”€ ğŸ“œ SCRIPTS (Optimized v2.0)
â”‚   â”œâ”€â”€ optimized_feature_extraction.py  # Feature extraction + augmentation
â”‚   â”œâ”€â”€ optimized_cnn_model.py           # 3 CNN architectures (Simple/Deep/Attention)
â”‚   â”œâ”€â”€ optimized_train.py               # Training script with K-Fold CV
â”‚   â”œâ”€â”€ app_optimized.py                 # Streamlit web application (with auth)
â”‚   â””â”€â”€ setup_auth.py                    # Authentication setup script
â”‚
â”œâ”€â”€ ğŸ” AUTHENTICATION
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ __init__.py                  # Auth package
â”‚   â”‚   â”œâ”€â”€ authenticator.py             # Login/logout logic
â”‚   â”‚   â”œâ”€â”€ password_utils.py            # Password hashing
â”‚   â”‚   â”œâ”€â”€ database.py                  # SQLite operations
â”‚   â”‚   â””â”€â”€ users.db                     # User credentials (NOT in git)
â”‚   â””â”€â”€ AUTH_README.md                   # Authentication documentation
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                        # This file
â”‚   â”œâ”€â”€ AUTH_README.md                   # Authentication guide
â”‚   â”œâ”€â”€ FLUTTER_MOBILE_GUIDE.md          # Mobile deployment guide
â”‚   â”œâ”€â”€ PROJECT_CHECKPOINT.md            # Project continuity doc
â”‚   â””â”€â”€ ANALYSIS_REPORT.md               # Technical analysis
â”‚
â”œâ”€â”€ ğŸ› ï¸ UTILITIES
â”‚   â”œâ”€â”€ compare_models.py                # Model benchmarking tool
â”‚   â”œâ”€â”€ show_results.py                  # Training results viewer
â”‚   â”œâ”€â”€ check_data.py                    # Data statistics
â”‚   â”œâ”€â”€ convert_to_tflite.py             # TFLite model converter
â”‚   â””â”€â”€ QUICK_START.py                   # Interactive guide
â”‚
â”œâ”€â”€ âš™ï¸ CONFIGURATION
â”‚   â”œâ”€â”€ requirements_optimized.txt       # Python dependencies
â”‚   â””â”€â”€ .gitignore                       # Git ignore rules
â”‚
â””â”€â”€ ğŸ“‚ DATA (Not included in repo)
    â”œâ”€â”€ dataset_amino/                   # Raw audio files
    â”œâ”€â”€ models/                          # Trained models (.h5, .tflite)
    â”œâ”€â”€ processed_data_optimized.npz     # Processed features
    â”œâ”€â”€ visualizations/                  # Training graphs
    â”œâ”€â”€ logs/                            # Training & login logs
    â””â”€â”€ backups/                         # Database backups

```

---

## ğŸš€ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/mastoro786/CNN_amino.git
cd CNN_amino
```

### 2. Setup Environment

```bash
# Create virtual environment
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate

# Activate (Linux/Mac)
source .venv/bin/activate

# Install dependencies
pip install -r requirements_optimized.txt
```

### 3. Prepare Dataset

Place your audio files in the following structure:

```
dataset_amino/
â”œâ”€â”€ normal/
â”‚   â”œâ”€â”€ audio1.wav
â”‚   â”œâ”€â”€ audio2.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ skizofrenia/
    â”œâ”€â”€ audio1.wav
    â”œâ”€â”€ audio2.wav
    â””â”€â”€ ...
```

### 4. Extract Features

```bash
python optimized_feature_extraction.py
```

**Output**: `processed_data_optimized.npz` (~145 MB)

### 5. Setup Authentication (NEW!)

```bash
# Initialize database and create default users
python setup_auth.py
```

**Default Credentials** (âš ï¸ Change immediately after first login!):
| Username | Password | Role |
|----------|----------|------|
| `admin` | `Admin123` | Administrator |
| `dr_amino` | `Doctor123` | Doctor |
| `staff1` | `Staff123` | Staff |

ğŸ“– **Full Authentication Guide**: See [AUTH_README.md](AUTH_README.md)

### 6. Train Model

```bash
python optimized_train.py
```

**Configuration** (edit in script):
```python
MODEL_TYPE = 'deep'      # 'simple', 'deep', or 'attention'
EPOCHS = 150
BATCH_SIZE = 16
```

**Output**: 
- `models/best_model.h5` - Trained model
- `visualizations/` - Training graphs
- `logs/` - Training logs

### 7. Run Web Application

```bash
streamlit run app_optimized.py
```

**Access**: http://localhost:8501

**Login** with the credentials above (change password after first login!)

### 8. Convert to TFLite (Optional - For Mobile)

---

## ğŸ“Š Model Architectures

### Simple CNN (800K params)
- Fast training (~10-15 min)
- Good for small datasets
- Expected accuracy: 88-92%

### Deep CNN (3M params) â­ **Recommended**
- Best performance
- Production-ready quality
- Expected accuracy: 92-96%
- **Achieved: 93.48%**

### Attention CNN (2M params)
- Experimental
- Attention mechanism
- Expected accuracy: 90-94%

---

## ğŸ”§ Advanced Usage

### K-Fold Cross Validation

For robust evaluation:

```python
# Edit optimized_train.py
USE_KFOLD = True
K_FOLDS = 5
```

### Multi-Modal Features

Extract richer features:

```python
# Edit optimized_feature_extraction.py
USE_MULTI_FEATURES = True
```

Features extracted:
- Mel Spectrogram (128 bands)
- MFCC (40 coefficients)
- Chroma (12 bins)
- Spectral Contrast (7 bands)

---

## ğŸ“ˆ Training Results

### Convergence
- **Best Epoch**: 34/62
- **Early Stopping**: Worked perfectly
- **No Overfitting**: -2.37% gap (validation > training)

### Metrics Evolution
```
Initial  â†’ Final
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Accuracy:  53% â†’ 93.48%
Loss:      2.5 â†’ 1.42
Precision: 40% â†’ 87.50%
Recall:    69% â†’ 100%
```

### Visualizations

Training graphs saved in `visualizations/`:
- `training_history.png` - Loss & accuracy curves
- `confusion_matrix.png` - Error analysis
- `roc_curve.png` - ROC-AUC curve
- `pr_curve.png` - Precision-Recall curve

---

## ğŸ’» Web Application Features

### Modern UI
- ğŸ¨ Gradient header with purple theme
- ğŸ“Š **Gauge meter** showing confidence score
- ğŸ“ˆ **Horizontal bar chart** for class probabilities
- ğŸµ Waveform and spectrogram visualization
- ğŸ“± Responsive design

### Prediction Display
- Color-coded results (Green = Normal, Red = Skizofrenia)
- Confidence percentage
- Detailed interpretation based on confidence level
- Audio statistics (duration, RMS energy, etc.)

---

## ğŸ”¬ Technical Details

### Data Augmentation

5 techniques applied randomly (2-3 per sample):

1. **Add Noise**: Gaussian noise (0.2-1%)
2. **Time Shift**: Â±0.3 seconds
3. **Pitch Shift**: Â±3 semitones
4. **Time Stretch**: 0.85-1.15x speed
5. **Reverb**: Simple impulse response

**Result**: 109 files â†’ 226 samples (after augmentation)

### Training Strategy

- **Optimizer**: Adam (LR=0.0001)
- **Loss**: Binary Crossentropy
- **Batch Size**: 16
- **Early Stopping**: Patience=25 epochs
- **ReduceLROnPlateau**: Factor=0.5, Patience=10
- **Class Weights**: Auto-computed for imbalance

### Regularization

- Dropout: 0.25 â†’ 0.5 (progressive)
- Batch Normalization: After each conv layer
- L2 Regularization: 0.001
- Global Average Pooling

---

## ğŸ“ Citation

If you use this project in your research, please cite:

```bibtex
@software{cnn_audio_schizophrenia,
  title={CNN-based Audio Classification for Schizophrenia Detection},
  author={RSJD dr. Amino Gondohutomo},
  year={2025},
  url={https://github.com/mastoro786/CNN_amino}
}
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### Development Setup

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **RSJD dr. Amino Gondohutomo** for providing the dataset and domain expertise
- **TensorFlow/Keras** team for the deep learning framework
- **Librosa** team for audio processing capabilities
- **Streamlit** team for the amazing web framework

---

## ğŸ“ Contact

For questions or collaborations:

- **Email**: [Your email]
- **Institution**: RSJD dr. Amino Gondohutomo
- **GitHub**: [@mastoro786](https://github.com/mastoro786)

---

## âš ï¸ Disclaimer

**IMPORTANT**: This system is designed as a **screening tool only**. The predictions should **NOT** be used as a sole basis for clinical diagnosis. Always consult with qualified mental health professionals for accurate diagnosis and treatment.

---

<div align="center">

**Built with â¤ï¸ using Python, TensorFlow, and Streamlit**

â­ Star this repo if you find it helpful!

</div>
